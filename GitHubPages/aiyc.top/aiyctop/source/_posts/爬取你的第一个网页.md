---
title: 爬取你的第一个网页
tags: []
id: '806'
categories:
  - - Python3 网络爬虫系统教学
date: 2020-08-13 08:33:58
---

从本篇开始，我们正式开始学习 Python 网页爬虫的相关知识。 通过上面两篇基础教程的学习，相信大部分的小伙伴都了解了 Python 和 HTML 的相关开发技术，也可能有一小部分的同学因为刚学习新的知识，还没有完全明白，就迫不及待的点开了这篇文章。无论怎样，在正式学习网页爬虫的相关文章中，我都会力求详细，对一些之前没有讲解过、讲解的不够细致的点再次复习，将 Python 网页爬虫的学习坡度降到最低。 本篇使用 Python 自带的 urllib 模块抓取简单的网页，在这过程中为读者提供一个较为详细的网页爬虫过程。

## 1\. 使用 urllib 爬取网页

urllib 是 Python 中自带的一个用于网页信息获取的模块，这也就意味着你可以直接使用它来爬取网页信息，让我们看下面的这个小例子：

```python
import urllib.request
response = urllib.request.urlopen('http://gitbook.cn/')
html = response.read()
print(html)
```

运行上述代码，我们可以得到的信息是：

```python
b'<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, user-scalable=no"><title>GitChat</title><meta name="description" content="GitChat ....
```

Great！你已经成功的写出了第一个网页爬虫程序！让我们赶快看一下你写的代码每一行代表什么意思吧！

```python
import urllib.request 
```

import 是一个 Python 关键字。Python 自带了很多的功能，但如果一下子全部加载在程序里，那将大大增加时间，降低运行效率。因此，Python 将一部分功能封装成一个个模块，只有当你真正需要时，自己导入，编译的时候才会帮你加载这部分的内容。这里我们导入的是 `urllib.request` 模块。

```python
response = urllib.request.urlopen('http://gitbook.cn/')
```

当我们在上面成功导入了 `urllib.request` 模块后，我们就可以调用它包含的函数啦！`urlopen()`就是我们加载的模块中的一个函数，它的作用是打开一个代表网页的 URL，并返回一个“类似文件”的对象。

```python
html = response.read()
```

看到这里是不是很熟悉？没错！通过 `urlopen()` 函数，变量 response 成为了一个文件！我们读取一个文件的内容时，用的就是 read() 函数！

```python
print(html)
```

变量 `html` 已经被赋值为网页的内容，让我们直接打印它就行啦！怎么样？是不是很简单！

## 2\. “欺骗”服务器传输数据

趁着知识刚学完，让我们再写一个网页爬虫程序，爬取百度的首页吧！让我们开始 Coding！

```python
import urllib.request
response = urllib.request.urlopen('https://www.baidu.com/')
html = response.read()
print(html)
```

这也太简单了吧！让我们直接运行一下看看我们日常使用的百度首页内容有哪些：

```python
urllib.error.HTTPError: HTTP Error 502: Bad Gateway
```

啊哦，系统报错了！让我们仔细看看这个 `HTTP Error 502`是什么意思吧：

> 502 ：错误网关，服务器作为网关或者代理，从上游服务器收到无效响应。

在讲解怎么解决该问题之前，我们需要理解这样一个概念：当我们访问一个网页的时候，我们使用的是浏览器软件。目前市面上有很多浏览器软件，例如 Chrome、FireFox、IE 等。不同浏览器之间，其展示网页的格式也有可能不相同。那么如何解决这种问题呢？ 如下图所示，其实当我们访问网页的时候，我们传输的访问请求上，已经写入了浏览器的相关信息。 ![图1-UserAgent](https://images-aiyc-1301641396.cos.ap-guangzhou.myqcloud.com/20200813083151.png) 让我们想象这样一个情况：你是一家大型网站的 CTO，你的网站本身流量就很大。因为你的网站结构合理、布局清晰，很多网页爬虫爱好者都爱爬取你的网站。你会不会很崩溃？ 为了“干掉”一些新手（就像现在的我们），你索性在响应请求的时候，加入了请求是不是通过浏览器访问的判断：如果请求中存在浏览器的相关信息，就返回数据；如果请求只是光秃秃的请求 URL，那就不“理睬”它。 听完了上面的假设，你是不是想到了为什么会有 502 错误了呢？没错，因为网站认为你没有用浏览器！那么有没有什么方法解决这个问题呢？当然有啦！俗话说：道高一尺，魔高一丈。虽然我们不是魔鬼，但是我们也可以踩着“魔鬼的步伐”，顺利的解决这个“难题”！

```python
import urllib.request
req = urllib.request.Request('https://www.baidu.com/')
req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36')
web = urllib.request.urlopen(req)
file = web.read()
print(file)
```

修改后的代码，多了两行，我们来解释一下这两行的代码：

```python
req = urllib.request.Request('https://www.baidu.com/')
```

我们使用了 `urllib.request.Request()` 这个函数，除了 URL ，该函数还有其他的参数，感兴趣的可以[在这里查阅它的文档](https://docs.python.org/3/library/urllib.request.html#module-urllib.request)，我们可以简单的认为，这是一个 URL 请求的抽象。

```python
req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36')
```

函数 `add_header()` 用来“欺骗”服务器——我是通过浏览器访问网站的，请返回给我相关的数据。可以看到，函数里面相关字符串，是我们上面提到的浏览器标记数据。

## 3\. 爬取中文网站的正确姿势

是不是到现在，虽然完成了你的第二个网页爬虫的程序，还是感觉不对劲？亦或者是，当你兴致勃勃的翻了翻你爬取内容时候，一副生无可恋的样子：为什么没有中文字？为什么都是类似于 `\xa8` 这样的代码？ 恭喜你已经具有了开发人员主动思考问题的的思维！没错，和英文不一样的是，中文的编码格式有很多，ASCII、GB2312、UTF-8、Unicode……如果我们不对网页信息进行正确的编码，那么最后显示的结果，也必将是乱码。 那么，如何知道网站的编码，爬取的时候如何对其进行重新编码呢？ 首先，目前的大部分网页都会在 HTML 代码中，写入网页的编码，我们可以方便的获取到相应的编码格式。 记得这篇文章说过的一句话吗？

> `urlopen()` 就是我们加载的模块中的一个函数，它的作用是打开一个代表网页的 URL，并返回一个“类似文件”的对象。

没错！我们可以直接对获取到的网页信息，按照文件编码的方法对其进行正确的编码，其代码也就成为了下面这样：

```python
import urllib.request
req = urllib.request.Request('https://www.baidu.com/')
req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36')
web = urllib.request.urlopen(req)
file = web.read().decode("utf-8")  #对网页信息进行编码
print(file)
```

让我们来运行一下修改后的程序：

```python
......
<title>百度一下，你就知道</title>
......
```

果然，中文终于正常显示了！我们终于从什么都不懂的“爬虫小白”，成功进阶到“中英文网站全制霸”的“爬虫新手”了！

## 4\. 相关提醒

这篇文章使用的是 Python 自带的 urllib 模块。其实，不仅仅是 urllib，Python 还有 urllib2 模块。但是在 Python3 的版本中，这两个模块合并为一，很大程度上降低了开发的成本； 通过这篇文章，我们知道：有的服务器是拒绝脚本获取数据的，我们需要模拟浏览器，去“欺骗”服务器。这是一种常见，甚至是约定俗成的反爬虫方法，在接下来的网页爬虫技术中，我们默认都会加上这段代码。 虽然本篇文章解决了中文的编码问题，但是要注意的是：现实中，大型网页爬虫程序所要面对的编码问题，往往比这复杂的多得多得多，不是一个量级的。这篇文章仅仅是为读者提供一个解决的思路而已。 如果课后有时间，推荐阅读一下[《常见的HTTP响应状态码》](http://tool.oschina.net/commons?type=5)和[《中文编码问题》](https://www.cnblogs.com/zkp2010/p/5510767.html)等相关文章。

### 4.1 《常见的HTTP响应状态码》

状态码

含义

100

客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。

101

服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。 　　只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。

102

由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。

200

请求已成功，请求所希望的响应头或数据体将随此响应返回。

201

请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 '202 Accepted'。

202

服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。 　　返回202状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。

203

服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。

204

服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。 　　如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 　　由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。

205

服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。 　　与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。

206

服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 　　该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。 　　响应必须包含如下的头部域： 　　Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。 　　Date 　　ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。 　　Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 　　假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。 　　假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。 　　任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。

207

由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。

300

被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 　　除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。 　　如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。

301

被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。 　　新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 　　注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个301响应的话，接下来的重定向请求将会变成 GET 方式。

302

请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 　　新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 　　注意：虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将302响应视作为303响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码303和307被添加了进来，用以明确服务器期待客户端进行何种反应。

303

对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 　　新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动，302状态码应该可以胜任，因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的。

304

如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 　　该响应必须包含以下的头信息： 　　Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068中规定的一样），缓存机制将会正常工作。 　　ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 　　Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 　　假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。 　　假如某个304响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。 　　假如接收到一个要求更新某个缓存条目的304响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。

305

被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。 　　注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。

306

在最新版的规范中，306状态码已经不再被使用。

307

请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 　　新的临时性的URI 应当在响应的 Location 域中返回。除非这是一个HEAD 请求，否则响应的实体中应当包含指向新的URI 的超链接及简短说明。因为部分浏览器不能识别307响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 　　如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。

400

1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。 　　2、请求参数有误。

401

当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617。

402

该状态码是为了将来可能的需求而预留的。

403

服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。

404

请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。

405

请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 　　鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。

406

请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。 　　除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。

407

与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见RFC 2617。

408

请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。

409

由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。 　　冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个409错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。

410

被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用404状态码。除非额外说明，否则这个响应是可缓存的。 　　410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为'410 Gone'，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。

411

服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。

412

服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。

413

服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 　　如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。

414

请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括： 　　本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。 　　重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。 　　客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行\[1\]。没有此类漏洞的服务器，应当返回414状态码。

415

对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。

416

如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。 　　假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。

417

在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。

421

从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。

422

从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。

422

请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 　　当前资源被锁定。（RFC 4918 WebDAV）

424

由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV）

425

在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。

426

客户端应当切换到TLS/1.0。（RFC 2817）

449

由微软扩展，代表请求应当在执行完适当的操作后进行重试。

500

服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。

501

服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。

502

作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。

503

由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。 　　注意：503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。

504

作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 　　注意：某些代理服务器在DNS查询超时时会返回400或者500错误

505

服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。

506

由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。

507

服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918)

509

服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。

510

获取资源所需要的策略并没有没满足。（RFC 2774）

### 4.2 中文编码问题

**一、为什么要编码？** 计算机储存信息的最小单元是1个字节，能表示的字符范围是0-255 我们要表示的字符号太多，1个字节远远不够，因此要有一个新的类型char,从char到byte必须编码。 **二、常见编码格式有哪些？**

1.  ASCII码 用一个字节的低7位表示，00-7F (即0-127)范围，0-31是回车、换行、删除等控制字符，32-126 是打印字符，可以用键盘输入并显示出来。
    
2.  ISO-8856-1 ASCII码共 128 个字符是远远不够的，ISO 组织又制定了这个标准。以单字节表示，共 256 个字符。对于英文字符是足够了。
    
3.  GB2312 中文全称为 “信息交换用汉字编码字符集” ，双字节的。GB2312 共收录有 7445 个字符，其中简化汉字 6763 个，字母和符号 682 个
    
4.  GBK 全称“汉字内码扩展规范”，为了扩展 GB2312，故兼容 GB2312，能表示21003个汉字。
    
5.  GB18030 是我国强制标准，但实际应用系统并不多。
    
6.  UTF-16 Unicode，是 ISO 视图创建一个全新的超语言字典，可以互相翻译全世界所有语言。UTF-16 定义了 Unicode 在计算机的存取方法，用两个字节表示 Unicode 的转化格式，两个字节是16位，故叫 UTF-16。UTF-16 表示字符很方便，简化了字符串操作，**因此Java 以 UTF-16 作为内存的字符存储格式**。
    
7.  UTF-8 UTF-16统一用量个字节表示一个字符，虽然表示很简单方便，但缺点是很大一部分字符可以用一个字节表示，缺占了两个字节，存储空间上放大了一倍。在网络带宽有限的情况下，增大网络流量。UTF-8采用变长技术，不同类型的字符可以由1-6个字节组成。**故网络编码多用 UTF-8**
    

**编码格式对比，GB2312 与 GBK，GBK 范围更大，选 GBK。** UTF-8 与 UTF-16，UTF-16 的编码效果高，转换简单，适合在内存和磁盘中操作，JAVA 内存编码就是 UTF-16。 对于网络传输，容易损坏字节流，加上传输量因素，选择UTF-8更好。编码效率而言，GBK<UTF-8<UTF-16，故中文编码的网络传输采用UTF-8最理想。 **三、JAVA中要编码的场景**

1.  磁盘IO操作 文件读写类，FileOutputStream 和 FileInputStream,只要统一设置编解码字符集，一般不会出现乱码问题。要注意的是有些应用程序不指定编码格式，中文环境中会用操作系统默认编程，换成其他操作系统环境可能会出问题。强烈建议指定编码格式。
    
2.  内存操作中 String 和 byte\[\] 的互相转换，设置统一编解码格式也不会出现问题。
    
3.  Java Web 中的编码，这个问题是重中之重 从使用中文角度来说，有IO的地方就有编码。网络传输中是以字节为单位的，所有数据都要能被序列化成字节。 (1) URL编码 从浏览器发情一次HTTP请求，存在编码的地方是 URL、Cookie、Paramiter 完整URL：http://localhost:8080/oa/base/userServlet/张三.do?name=张三
    

Domain:localhost port:8080 ContextPath:oa ServletPath:base/userServlet PathInfo:张三.do QueryString:name=张三 URI部分：oa/base/userServlet/张三.do 以谷歌浏览器为例，F12打开调试，可以看到是UTF-8编码的。 chrome下无论请求地址和参数，均经过utf-8编码;但其他浏览器不一定是这样，比如IE是GBK编码。 ![img](https://images-aiyc-1301641396.cos.ap-guangzhou.myqcloud.com/20200813083201.jpg) 如360浏览器，请求地址是这样，PathInfo是GBK编码，QueryString是utf-8编码.可能你的结果不同，但是PathInfo和QueryString编码不同是存在的。 http%3A%2F%2Flocalhost%3A8080%2Foa%2Fbase%2FuserServlet%2F**%D5%C5%C8%FD%2E**do%3Fname%3D**%25E5%25BC%25A0%25E4%25B8%2589** 编码和解码不是程序中能完全控制的，所以要尽量避免在 URL 中使用非 ASCII 字符。最好在服务端设置。以 tomcat 为例 在 tomcat 的 server.xml 下的 connetor 属性中增加 URIEncoding 或者 useBodyEncodingForURI 属性，如果不设置则 tomcat 按默认ISO-8856-1 来解码。 (2) HTTP Header编码 浏览器发起 http请求，Header中cookie等参数也存在编码问题。tomcat从byte到char转化同样默认是ISO-8856-1。 (3)POST表单的编解码 在页面点提交按钮时，先根据ContentType对表单填写项编码，在服务端同样用这个编码来解码，一般不会有问题。这个编码个是我们程序可以控制的，如rquset.setCharacterEncoding(charset)。如果不设置，按系统默认编码来解析。包括上传文件也是字节流。 (4)HTTP BODY 这些内容通过Response返回给客户端浏览器。也是先经过编码，再到浏览器解码。可以通过response.setCharacterEncoding(charset)设置，浏览器客户端根据 html 中的 `<meta http-equiv=content-type content="text/html; charset=utf-8">`来解码 4，Js中的编码 如果外部js文件与当前页面编码不一致，可能会出现编码问题。所以统一引入 js文件时加编码

```javascript
<script type ="text/javascript" src="resource/js/ueditor/ueditor.config.js" charset="utf-8" ></script>
```

js发起一步调用的URL也受浏览器影响，也要encodeURI()这样的函数来UTF-8编码，彻底解决编码问题 5，Js编码，后台java解码 自然全部UTF-8 6，其他 开发环境IDE，设置文件的编码格式。 xml 设置, jsp contentType="text/html; charset=UTF-8" **四、常见问题分析**

1.  一个汉字变成两个乱码字符 字节数没丢，说明编码没错可能是GBK，解码用了ISO-8856-1。
    
2.  每个汉字变成一个问号 如："天气很好" 变成 "? ? ? ?"。编码时字节丢失，使用了ISO-8856-1，码值为3F，ISO-8856-1解码时都变成3F对应的?号
    
3.  一个汉字变成两个问号 如："天气很好" 变成 "? ? ? ? ? ? ? ?"这种比较复杂，中文经过多次编码，有一次编码或解码使用了ISO-8856-1。要每个编解码环节仔细查看。
    
4.  国际化问题
    
    首先要用支持多语言的UTF-8编码，又一个使用 UTF-8 的必要性。国际化有 springi18 见其他相关文章。